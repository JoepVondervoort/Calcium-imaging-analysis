# Comprehensive Calcium Imaging Data Analysis with Statistical Annotations
# This script includes outlier handling, professional plotting, statistical tests, and clear visualization with annotations

import os
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.signal import find_peaks, peak_widths
from scipy.stats import linregress, kruskal, mannwhitneyu, shapiro

# 1. Calculate kinetics from CSV
def calculate_kinetics_peaks(file_path):
    data = pd.read_csv(file_path, header=None, skiprows=1)
    frame_col, roi_cols = 0, data.columns[1:]

    results = []
    for roi_col in roi_cols:
        frames, intensity = data[frame_col].dropna().values, data[roi_col].dropna().values
        if len(frames) < 2 or len(intensity) < 2:
            continue

        baseline = np.mean(intensity)
        if baseline <= 0:
            continue

        dff = (intensity - baseline) / baseline
        peaks, _ = find_peaks(dff, prominence=0.1, distance=2)

        amplitude = np.mean(dff[peaks]) if peaks.size else 0
        slope = linregress(frames, dff).slope if peaks.size else 0
        widths, _, _, _ = peak_widths(dff, peaks, rel_height=0.5)
        fwhm_val = np.mean(widths) if widths.size else 0

        results.append({'NumPeaks': len(peaks), 'Amplitude': amplitude, 'Slope': slope, 'FWHM': fwhm_val})
    return results

# 2. Parse filename
def parse_filename(filename):
    pattern = r"^(\d{8})_(WT|Nav|PTZ|Vera)(\d*)\.(\d+)"
    match = re.match(pattern, filename.replace('.Results.csv',''))
    if not match:
        return None, None, None, None
    date_str, condition, replicate, meas = match.groups()
    replicate, meas = int(replicate or 0), int(meas[0])
    return date_str, condition, replicate, meas

# 3. Collect data
def collect_data(folder_path):
    data = []
    for file in os.listdir(folder_path):
        if file.endswith('.csv'):
            path = os.path.join(folder_path, file)
            date, cond, rep, meas = parse_filename(file)
            if not date:
                continue
            kinetics = calculate_kinetics_peaks(path)
            for k in kinetics:
                k.update({'Date': date, 'Condition': cond, 'Replicate': rep, 'Measurement': meas})
                data.append(k)
    return pd.DataFrame(data)

# 4. Outlier removal using IQR with explanation
def remove_outliers(df, metric):
    Q1, Q3 = df[metric].quantile([0.25, 0.75])
    IQR = Q3 - Q1
    lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
    return df[(df[metric] >= lower) & (df[metric] <= upper)]

# 5. Statistical analysis with annotations
def statistical_analysis(df, metric, conditions):
    analysis_summary = []

    # Normality test
    normality = {cond: shapiro(df[df['Condition'] == cond][metric])[1] for cond in conditions}
    analysis_summary.append(f"Normality p-values: {normality}\n")

    # Kruskal-Wallis test
    kw_p = kruskal(*(df[df['Condition']==cond][metric] for cond in conditions)).pvalue
    analysis_summary.append(f"Kruskal-Wallis p-value: {kw_p:.4e}\n")

    # Pairwise Mann-Whitney
    pairwise_results = []
    for i, cond1 in enumerate(conditions):
        for cond2 in conditions[i+1:]:
            p_val = mannwhitneyu(df[df['Condition']==cond1][metric], df[df['Condition']==cond2][metric]).pvalue
            significant = 'Yes' if p_val < 0.05 else 'No'
            pairwise_results.append(f"{cond1} vs {cond2}: p={p_val:.4e}, significant={significant}")

    analysis_summary.extend(pairwise_results)
    return "\n".join(analysis_summary)

# 6. Plotting with statistics and annotations
def plot_data(df, output_folder):
    os.makedirs(output_folder, exist_ok=True)

    metrics = ['NumPeaks', 'Amplitude', 'Slope', 'FWHM']
    conditions = ['WT', 'Nav', 'PTZ', 'Vera']

    for meas in sorted(df['Measurement'].unique()):
        df_meas = df[df['Measurement'] == meas]
        df_active = df_meas[df_meas['NumPeaks'] >= 2]

        for metric in metrics:
            df_clean = remove_outliers(df_active, metric)

            plt.figure(figsize=(8,6))
            sns.violinplot(x='Condition', y=metric, data=df_clean, order=conditions, inner=None, palette='Set2')
            means = df_clean.groupby('Condition')[metric].mean()
            for i, cond in enumerate(conditions):
                plt.plot([i-0.2, i+0.2], [means[cond]]*2, color='red', lw=3)
                n = df_clean[df_clean['Condition'] == cond].shape[0]
                plt.text(i, plt.gca().get_ylim()[0], f'N={n}', ha='center', fontsize=9, color='black')

            analysis_summary = statistical_analysis(df_clean, metric, conditions)
            plt.title(f'{metric} (Meas {meas})', fontsize=14)
            plt.xlabel('')
            plt.ylabel(metric, fontsize=12)

            plt.tight_layout()
            plt.savefig(os.path.join(output_folder, f'{metric}_Meas_{meas}_violin.png'), dpi=300)
            plt.close()

            with open(os.path.join(output_folder, f'{metric}_Meas_{meas}_stats.txt'), 'w') as f:
                f.write(analysis_summary)

if __name__ == '__main__':
    input_folder = input('Enter CSV folder path: ').strip()
    output_folder = input('Enter results folder path: ').strip()

    df = collect_data(input_folder)
    print(f'Data collected ({len(df)} records)')

    plot_data(df, output_folder)
    print('Analysis complete and saved.')
