{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed188ac",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Count peaks per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffff6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "\n",
    "def analyze_calcium_data(filename):\n",
    "    # Read the data from the text file\n",
    "    data = pd.read_csv(filename, delimiter='\\t', header=None, skiprows=1)\n",
    "\n",
    "    # Get the column names for ROIs\n",
    "    roi_columns = list(data.columns[1:])\n",
    "\n",
    "    # Create a dictionary to store peak information for each ROI\n",
    "    roi_peaks = {}\n",
    "\n",
    "    # Iterate over each ROI\n",
    "    for roi in roi_columns:\n",
    "        # Get the data for the current ROI\n",
    "        roi_data = data[[0, roi]].dropna().reset_index(drop=True)\n",
    "        frames = roi_data[0]\n",
    "        intensity = roi_data[roi]\n",
    "\n",
    "        # Calculate ▲F/F\n",
    "        baseline = intensity.mean()\n",
    "        dff = (intensity - baseline) / baseline\n",
    "\n",
    "        # Find peaks using the saw shape pattern criteria\n",
    "        peaks, _ = find_peaks(dff, distance=50, prominence=0.1, width=50)\n",
    "\n",
    "        # Plot the ▲F/F with detected peaks (wider plot)\n",
    "        plt.figure(figsize=(12, 6))  # Set figsize to make the plot wider\n",
    "        plt.plot(frames, dff, color='black')  # Set line color to black\n",
    "        plt.plot(frames[peaks], dff[peaks], 'ro')  # Set peaks as red circles\n",
    "        plt.xlabel('Frames')\n",
    "        plt.ylabel('▲F/F')\n",
    "        plt.title(f'ROI: {roi}')\n",
    "        \n",
    "        # Manually set y-axis limits to ensure all data points are visible\n",
    "        plt.ylim([dff.min() - 0.1, dff.max() + 0.1])\n",
    "        \n",
    "        # Show the current plot\n",
    "        plt.show()\n",
    "\n",
    "        # Store peak information for the current ROI\n",
    "        roi_peaks[roi] = len(peaks)\n",
    "\n",
    "        # Close the current figure to prevent memory issues\n",
    "        plt.close()\n",
    "\n",
    "    return roi_peaks\n",
    "\n",
    "# Rest of your code remains unchanged\n",
    "\n",
    "\n",
    "def generate_data_frames(roi_peaks):\n",
    "    # Combine peak counts for all ROIs\n",
    "    total_peaks = sum(roi_peaks.values())\n",
    "\n",
    "    # Create DataFrame 1: Total peaks, active cells, average peak per active cell\n",
    "    active_rois = [roi for roi, peaks in roi_peaks.items() if peaks > 0]\n",
    "    active_cells = len(active_rois)\n",
    "    average_peak = total_peaks / active_cells if active_cells > 0 else 0\n",
    "\n",
    "    df1 = pd.DataFrame({'Total Peaks': [total_peaks],\n",
    "                        'Active Cells': [active_cells],\n",
    "                        'Average Peak per Active Cell': [average_peak]})\n",
    "\n",
    "    # Create DataFrame 2: ROIs with peaks and their counts\n",
    "    df2 = pd.DataFrame({'ROI': active_rois,\n",
    "                        'Peak Count': [roi_peaks[roi] for roi in active_rois]})\n",
    "\n",
    "    return df1, df2\n",
    "\n",
    "# New function to save DataFrames to Excel file\n",
    "def save_data_frames_to_excel(filename, df1, df2):\n",
    "    # Split the input filename to get the directory and base name\n",
    "    directory, base_name = os.path.split(filename)\n",
    "    \n",
    "    # Generate the output Excel file name (same name as input file)\n",
    "    output_filename = os.path.join(directory, f\"{os.path.splitext(base_name)[0]}.xlsx\")\n",
    "    \n",
    "    # Create a Pandas Excel writer using xlsxwriter as the engine\n",
    "    writer = pd.ExcelWriter(output_filename, engine='xlsxwriter')\n",
    "    \n",
    "    # Write each DataFrame to a specific sheet name\n",
    "    df1.to_excel(writer, sheet_name='DataFrame1', index=False)\n",
    "    df2.to_excel(writer, sheet_name='DataFrame2', index=False)\n",
    "    \n",
    "    # Save the Excel file\n",
    "    writer.save()\n",
    "\n",
    "# Change path here to which file you want to investigate:\n",
    "filename = 'H:/Calcium imaging/20230811/extracted_frames_total/Roi_files_stardist/Results/WT_ptz_1min_1_MM.txt'\n",
    "roi_peaks = analyze_calcium_data(filename)\n",
    "df1, df2 = generate_data_frames(roi_peaks)\n",
    "\n",
    "# Save the DataFrames to an Excel file\n",
    "save_data_frames_to_excel(filename, df1, df2)\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "print(f\"Data saved to {os.path.splitext(filename)[0]}.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c016e",
   "metadata": {},
   "source": [
    "# Combine all .txt files in a folder to analyse whole experiment all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df2ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def analyze_calcium_data(filename):\n",
    "    # Read the data from the text file\n",
    "    data = pd.read_csv(filename, delimiter='\\t', header=None, skiprows=1)\n",
    "\n",
    "    # Get the column names for ROIs\n",
    "    roi_columns = list(data.columns[1:])\n",
    "\n",
    "    # Create a dictionary to store peak information for each ROI\n",
    "    roi_peaks = {}\n",
    "\n",
    "    # Iterate over each ROI\n",
    "    for roi in roi_columns:\n",
    "        # Get the data for the current ROI\n",
    "        roi_data = data[[0, roi]].dropna().reset_index(drop=True)\n",
    "        frames = roi_data[0]\n",
    "        intensity = roi_data[roi]\n",
    "\n",
    "        # Calculate ▲F/F\n",
    "        baseline = intensity.mean()\n",
    "        dff = (intensity - baseline) / baseline\n",
    "\n",
    "        # Check for and handle NaN or Inf values in dff, This was done because in some cases because computers crashed\n",
    "        if np.any(np.isnan(dff)) or np.any(np.isinf(dff)):\n",
    "            print(f\"Skipping ROI {roi} due to NaN or Inf values.\")\n",
    "            continue\n",
    "\n",
    "        # Find peaks using the saw shape pattern criteria\n",
    "        peaks, _ = find_peaks(dff, height=0.01, distance=25, width=25)\n",
    "\n",
    "        # If there are no valid peaks, skip this ROI, This was done because in some cases because computers crashed\n",
    "        if len(peaks) == 0:\n",
    "            print(f\"No valid peaks found for ROI {roi}. Skipping.\") \n",
    "            continue\n",
    "\n",
    "        # Plot the ▲F/F with detected peaks (wider plot)\n",
    "        plt.figure(figsize=(10, 6))  # Set figsize to make the plot wider\n",
    "        plt.plot(frames, dff, color='black')  # Set line color to black\n",
    "        plt.plot(frames[peaks], dff[peaks], 'ro')  # Set peaks as red circles\n",
    "        plt.xlabel('Frames')\n",
    "        plt.ylabel('▲F/F')\n",
    "        \n",
    "        # Extract only the file name from the full path\n",
    "        file_name = os.path.basename(filename)\n",
    "        \n",
    "        # Set the title with just the file name and ROI number\n",
    "        plt.title(f'ROI: {roi} (File: {file_name})')\n",
    "        \n",
    "        # Manually set y-axis limits to ensure all data points are visible\n",
    "        plt.ylim([dff.min() - 0.1, dff.max() + 0.1])\n",
    "        \n",
    "        # Show the current plot\n",
    "        plt.show()\n",
    "\n",
    "        # Store peak information for the current ROI\n",
    "        roi_peaks[roi] = len(peaks)\n",
    "\n",
    "        # Close the current figure to prevent memory issues\n",
    "        plt.close()\n",
    "\n",
    "    # Add code to compute the total number of cells in the file\n",
    "    total_cells = len(roi_columns)  # Total number of ROIs is the total number of cells\n",
    "\n",
    "    return roi_peaks, total_cells\n",
    "\n",
    "def generate_data_frames(roi_peaks, source_file, total_cells):\n",
    "    # Create DataFrame 1: Total peaks, active cells, total peaks in active cells, average peak per active cell, % active cells\n",
    "    total_peaks = sum(roi_peaks.values())\n",
    "    \n",
    "    # Filter ROIs with more than two peaks to be considered active cells\n",
    "    active_cells = [roi for roi, peaks in roi_peaks.items() if peaks > 1]\n",
    "    \n",
    "    # Calculate the total peaks within active cells\n",
    "    total_peaks_active = sum([roi_peaks[roi] for roi in active_cells])\n",
    "\n",
    "    # Calculate the average peak per active cell based on active cells only\n",
    "    average_peak_active = total_peaks_active / len(active_cells) if len(active_cells) > 0 else 0\n",
    "    \n",
    "    # Calculate the percentage of active cells\n",
    "    percent_active_cells = (len(active_cells) / total_cells) * 100 if total_cells > 0 else 0\n",
    "\n",
    "    df1 = pd.DataFrame({'Total Peaks': [total_peaks],\n",
    "                        'Active Cells': [len(active_cells)],\n",
    "                        'Total Peaks in Active Cells': [total_peaks_active],\n",
    "                        'Average Peak per Active Cell': [average_peak_active],\n",
    "                        '% Active Cells': [percent_active_cells],\n",
    "                        'Total Cells': [total_cells],\n",
    "                        'Source File': [source_file]})\n",
    "\n",
    "    # Create DataFrame 2: ROIs with peaks and their counts\n",
    "    df2 = pd.DataFrame({'ROI': list(roi_peaks.keys()),\n",
    "                        'Peak Count': list(roi_peaks.values()),\n",
    "                        'Source File': [source_file] * len(roi_peaks)})\n",
    "\n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    # Initialize an empty list to store the dataframes from all files\n",
    "    all_dataframes = []\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "\n",
    "            # Analyze the calcium data for the current file\n",
    "            roi_peaks, total_cells = analyze_calcium_data(file_path)\n",
    "\n",
    "            # Generate dataframes for the current file\n",
    "            df1, df2 = generate_data_frames(roi_peaks, filename, total_cells)\n",
    "\n",
    "            # Append the dataframes to the list\n",
    "            all_dataframes.append((df1, df2))\n",
    "\n",
    "            # Print the dataframes for the current file\n",
    "            print(\"DataFrame 1:\")\n",
    "            print(df1)\n",
    "            print(\"\\nDataFrame 2:\")\n",
    "            print(df2)\n",
    "\n",
    "    # Concatenate all dataframes into one\n",
    "    final_df1 = pd.concat([df[0] for df in all_dataframes], ignore_index=True)\n",
    "    final_df2 = pd.concat([df[1] for df in all_dataframes], ignore_index=True)\n",
    "\n",
    "    # Save the concatenated dataframes to a single Excel file\n",
    "    output_filename = os.path.join(folder_path, \"Combined_results.xlsx\")\n",
    "    with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:\n",
    "        final_df1.to_excel(writer, sheet_name='DataFrame1', index=False)\n",
    "        final_df2.to_excel(writer, sheet_name='DataFrame2', index=False)\n",
    "\n",
    "    print(f\"Data saved to {output_filename}\")\n",
    "\n",
    "# Change the path here to what folder you want investigate:\n",
    "folder_path = 'H:/Calcium imaging/20231123/Results'\n",
    "process_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3ee53",
   "metadata": {},
   "source": [
    "## Replace \\ with /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a423787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:/Calcium imaging/20231123/Results\n"
     ]
    }
   ],
   "source": [
    "input_string = r\"H:\\Calcium imaging\\20231123\\Results\"\n",
    "\n",
    "# Replace backslashes with forward slashes\n",
    "output_string = input_string.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Print the modified string\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408daf33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
