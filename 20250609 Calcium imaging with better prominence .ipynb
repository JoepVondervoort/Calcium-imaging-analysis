{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Calcium Imaging Analysis Pipeline - Measurement 1 Only\n",
    "# ## Analyzes only the first measurement files\n",
    "# \n",
    "# This version:\n",
    "# 1. For RNA experiment: Only processes files with \"Meas1\"\n",
    "# 2. For Chemical experiment: Only processes files with \"1001\" \n",
    "# 3. No \"Other Measurements\" analysis\n",
    "# 4. Peak detection: prominence > 0.2, minimum separation = 5 frames\n",
    "# 5. Z-score outlier removal with threshold 3.0\n",
    "\n",
    "# ## Import Libraries and Setup\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Set backend before importing pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "from scipy.stats import linregress, kruskal, mannwhitneyu, shapiro, sem, ttest_ind, zscore\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'figure.dpi': 100,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'pdf.fonttype': 42,\n",
    "    'axes.grid': True\n",
    "})\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nAnalysis Parameters:\")\n",
    "print(\"- Peak detection: prominence > 0.2, minimum separation = 5 frames\")\n",
    "print(\"- Active cells: ≥ 2 peaks\")\n",
    "print(\"- Outlier removal: z-score method with threshold = 3.0\")\n",
    "print(\"- Statistics: Shapiro-Wilk test → Mann-Whitney U or t-test\")\n",
    "print(\"- Analyzing ONLY Measurement 1 files\\n\")\n",
    "\n",
    "\n",
    "# ## Define Core Functions\n",
    "\n",
    "def parse_filename(filename, experiment_type='RNA'):\n",
    "    \"\"\"\n",
    "    Parse filename to extract condition and measurement.\n",
    "    Only accepts Measurement 1 files.\n",
    "    \"\"\"\n",
    "    if experiment_type == 'RNA':\n",
    "        # For RNA, only accept files with \"Meas1\"\n",
    "        if 'Meas1' not in filename:\n",
    "            return None, None, None\n",
    "            \n",
    "        filename_lower = filename.lower()\n",
    "        \n",
    "        # Determine condition for RNA\n",
    "        if 'Scr' in filename or 'scr' in filename_lower or 'scrambled' in filename_lower:\n",
    "            condition = 'Control (Scr)'\n",
    "        elif 'siRNA' in filename or 'sirna' in filename_lower:\n",
    "            condition = 'siRNA'\n",
    "        elif 'saRNA' in filename or 'sarna' in filename_lower:\n",
    "            condition = 'saRNA'\n",
    "        else:\n",
    "            return None, None, None\n",
    "        \n",
    "        # Check for dose patterns to exclude\n",
    "        dose_patterns = ['µm', 'um', 'µl', 'ul']\n",
    "        has_dose = any(pattern in filename_lower for pattern in dose_patterns)\n",
    "        has_dose_number = any(num + 'µ' in filename or num + 'u' in filename_lower \n",
    "                             for num in ['100', '50', '25'])\n",
    "        \n",
    "        if has_dose and has_dose_number:\n",
    "            return None, None, None  # Skip dose files\n",
    "            \n",
    "        return condition, 1, experiment_type\n",
    "        \n",
    "    else:  # Chemical experiment\n",
    "        # For chemicals, only accept files with \"1001\"\n",
    "        if '1001' not in filename:\n",
    "            return None, None, None\n",
    "            \n",
    "        filename_lower = filename.lower()\n",
    "        \n",
    "        # Determine condition\n",
    "        if 'wt' in filename_lower:\n",
    "            condition = 'WT'\n",
    "        elif 'nav' in filename_lower:\n",
    "            condition = 'Nav1.1 activator'\n",
    "        elif 'ptz' in filename_lower:\n",
    "            condition = 'PTZ'\n",
    "        elif 'vera' in filename_lower or 'veratridine' in filename_lower:\n",
    "            condition = 'Veratridine'\n",
    "        else:\n",
    "            return None, None, None\n",
    "    \n",
    "        return condition, 1, experiment_type\n",
    "\n",
    "\n",
    "def calculate_kinetics_peaks(file_path):\n",
    "    \"\"\"\n",
    "    Calculate kinetics from CSV file with peak detection parameters.\n",
    "    Peak detection uses prominence > 0.2 and minimum separation of 5 frames.\n",
    "    Active cells are defined as having ≥ 2 peaks.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "    frame_col, roi_cols = 0, data.columns[1:]\n",
    "    \n",
    "    results = []\n",
    "    for roi_idx, roi_col in enumerate(roi_cols):\n",
    "        frames = data[frame_col].dropna().values\n",
    "        intensity = data[roi_col].dropna().values\n",
    "        \n",
    "        if len(frames) < 2 or len(intensity) < 2:\n",
    "            continue\n",
    "        \n",
    "        baseline = np.mean(intensity)\n",
    "        if baseline <= 0:\n",
    "            continue\n",
    "        \n",
    "        dff = (intensity - baseline) / baseline\n",
    "        if np.any(np.isnan(dff)) or np.any(np.isinf(dff)):\n",
    "            continue\n",
    "        \n",
    "        # Find peaks with specified parameters\n",
    "        peaks, properties = find_peaks(dff, prominence=0.2, distance=5, width=1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        amplitude = np.mean(dff[peaks]) if peaks.size else 0\n",
    "        slope = linregress(frames, dff).slope if peaks.size else 0\n",
    "        widths, _, _, _ = peak_widths(dff, peaks, rel_height=0.5)\n",
    "        fwhm_val = np.mean(widths) if widths.size else 0\n",
    "        \n",
    "        results.append({\n",
    "            'NumPeaks': len(peaks),\n",
    "            'Amplitude': amplitude,\n",
    "            'Slope': slope,\n",
    "            'FWHM': fwhm_val,\n",
    "            'IsActive': len(peaks) >= 2,  # Active if 2 or more peaks\n",
    "            'ROI_Index': roi_idx,\n",
    "            'FilePath': file_path\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def remove_outliers_zscore(df, metric, threshold=3.0):\n",
    "    \"\"\"\n",
    "    Remove outliers using z-score method with specified threshold.\n",
    "    Default threshold is 3.0 as per methodology.\n",
    "    \"\"\"\n",
    "    initial_count = len(df)\n",
    "    \n",
    "    # Calculate z-scores\n",
    "    z_scores = np.abs(zscore(df[metric]))\n",
    "    \n",
    "    # Keep only data within threshold\n",
    "    df_clean = df[z_scores < threshold].copy()\n",
    "    \n",
    "    removed = initial_count - len(df_clean)\n",
    "    if removed > 0:\n",
    "        print(f\"Removed {removed} outliers from {metric} using z-score method (threshold={threshold}, {removed/initial_count*100:.1f}%)\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "def collect_measurement1_data(folder_path, experiment_type='RNA'):\n",
    "    \"\"\"Collect data from folder - ONLY Measurement 1 files.\"\"\"\n",
    "    data = []\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "    parsing_log = []\n",
    "    \n",
    "    print(f\"Looking for CSV files in: {folder_path}\")\n",
    "    print(f\"Filtering for Measurement 1 only ({'Meas1' if experiment_type == 'RNA' else '1001'} files)\")\n",
    "    \n",
    "    # List all files found\n",
    "    all_csv_files = []\n",
    "    \n",
    "    # Use os.walk to handle both cases (files in root and in subfolders)\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(full_path, folder_path)\n",
    "                all_csv_files.append((file, full_path, relative_path))\n",
    "    \n",
    "    print(f\"Found {len(all_csv_files)} CSV files total\\n\")\n",
    "    \n",
    "    # Print parsing header\n",
    "    print(\"FILE PARSING DETAILS (Measurement 1 Only):\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Filename':<50} {'Condition':<20} {'Measurement':<15} {'Status':<15}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Track unique files to avoid duplicates\n",
    "    processed_paths = set()\n",
    "    \n",
    "    # Process each CSV file\n",
    "    for filename, full_path, rel_path in all_csv_files:\n",
    "        # Skip if already processed (avoid duplicates)\n",
    "        if full_path in processed_paths:\n",
    "            continue\n",
    "            \n",
    "        # Check if it's a results file\n",
    "        if 'results' in filename.lower() or experiment_type == 'Chemical':\n",
    "            condition, measurement, _ = parse_filename(filename, experiment_type)\n",
    "            \n",
    "            if condition is None or measurement is None:\n",
    "                skipped_files += 1\n",
    "                status = \"SKIPPED\"\n",
    "                reason = \"Not Meas1\" if experiment_type == 'RNA' and 'Meas' in filename and 'Meas1' not in filename else \"No valid condition or dose file\"\n",
    "                parsing_log.append({\n",
    "                    'filename': filename,\n",
    "                    'condition': 'N/A',\n",
    "                    'measurement': 'N/A',\n",
    "                    'status': status,\n",
    "                    'reason': reason\n",
    "                })\n",
    "                print(f\"{filename:<50} {'N/A':<20} {'N/A':<15} {status:<15}\")\n",
    "            else:\n",
    "                processed_files += 1\n",
    "                processed_paths.add(full_path)\n",
    "                status = \"PROCESSED\"\n",
    "                parsing_log.append({\n",
    "                    'filename': filename,\n",
    "                    'condition': condition,\n",
    "                    'measurement': str(measurement),\n",
    "                    'status': status,\n",
    "                    'reason': 'Success - Measurement 1'\n",
    "                })\n",
    "                \n",
    "                try:\n",
    "                    kinetics = calculate_kinetics_peaks(full_path)\n",
    "                    \n",
    "                    for k in kinetics:\n",
    "                        k.update({\n",
    "                            'Condition': condition,\n",
    "                            'Measurement': measurement,\n",
    "                            'File': filename,\n",
    "                            'FilePath': full_path\n",
    "                        })\n",
    "                        data.append(k)\n",
    "                    \n",
    "                    print(f\"{filename:<50} {condition:<20} {measurement:<15} {status:<15}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"{filename:<50} {condition:<20} {measurement:<15} ERROR: {str(e)[:30]}\")\n",
    "                    status = \"ERROR\"\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    print(f\"\\nSummary: Processed {processed_files} Measurement 1 files, skipped {skipped_files} files\")\n",
    "    print(f\"Collected {len(data)} ROIs from Measurement 1\\n\")\n",
    "    \n",
    "    # Create parsing log DataFrame\n",
    "    parsing_df = pd.DataFrame(parsing_log)\n",
    "    \n",
    "    return pd.DataFrame(data), parsing_df\n",
    "\n",
    "\n",
    "# ## Calcium Trace Visualization Functions\n",
    "\n",
    "def plot_calcium_traces(file_path, output_folder, max_traces_per_page=6):\n",
    "    \"\"\"\n",
    "    Plot calcium traces for all ROIs in a file with marked peaks.\n",
    "    Creates PDF files with multiple traces per page.\n",
    "    \"\"\"\n",
    "    # Read the data\n",
    "    data = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "    frame_col = 0\n",
    "    roi_cols = data.columns[1:]\n",
    "    \n",
    "    # Create PDF filename based on input filename\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    pdf_filename = os.path.join(output_folder, f\"{base_filename}_traces.pdf\")\n",
    "    \n",
    "    # Calculate total pages needed\n",
    "    total_rois = len(roi_cols)\n",
    "    total_pages = (total_rois + max_traces_per_page - 1) // max_traces_per_page\n",
    "    \n",
    "    with matplotlib.backends.backend_pdf.PdfPages(pdf_filename) as pdf:\n",
    "        roi_idx = 0\n",
    "        \n",
    "        for page in range(total_pages):\n",
    "            # Create figure with subplots\n",
    "            traces_on_page = min(max_traces_per_page, total_rois - roi_idx)\n",
    "            fig, axes = plt.subplots(traces_on_page, 1, figsize=(12, 2.5 * traces_on_page))\n",
    "            if traces_on_page == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            fig.suptitle(f'{base_filename} - Page {page + 1}/{total_pages}', fontsize=14, y=0.98)\n",
    "            \n",
    "            for i in range(traces_on_page):\n",
    "                roi_col = roi_cols[roi_idx]\n",
    "                ax = axes[i]\n",
    "                \n",
    "                # Get data\n",
    "                frames = data[frame_col].dropna().values\n",
    "                intensity = data[roi_col].dropna().values\n",
    "                \n",
    "                if len(frames) < 2 or len(intensity) < 2:\n",
    "                    ax.text(0.5, 0.5, 'No data', ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.set_xlabel('Frames')\n",
    "                    ax.set_ylabel('ΔF/F')\n",
    "                    roi_idx += 1\n",
    "                    continue\n",
    "                \n",
    "                # Calculate ΔF/F\n",
    "                baseline = np.mean(intensity)\n",
    "                if baseline <= 0:\n",
    "                    ax.text(0.5, 0.5, 'Invalid baseline', ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.set_xlabel('Frames')\n",
    "                    ax.set_ylabel('ΔF/F')\n",
    "                    roi_idx += 1\n",
    "                    continue\n",
    "                \n",
    "                dff = (intensity - baseline) / baseline\n",
    "                \n",
    "                # Plot the trace\n",
    "                ax.plot(frames, dff, 'k-', linewidth=1, alpha=0.8)\n",
    "                \n",
    "                # Find and mark peaks with specified parameters\n",
    "                peaks, properties = find_peaks(dff, prominence=0.2, distance=5, width=1)\n",
    "                \n",
    "                if len(peaks) > 0:\n",
    "                    # Mark peaks with red dots\n",
    "                    ax.plot(frames[peaks], dff[peaks], 'ro', markersize=6, label=f'{len(peaks)} peaks')\n",
    "                    \n",
    "                    # Add shaded regions around peaks\n",
    "                    for peak_idx in peaks:\n",
    "                        # Get peak width\n",
    "                        widths, width_heights, left_ips, right_ips = peak_widths(\n",
    "                            dff, [peak_idx], rel_height=0.5)\n",
    "                        \n",
    "                        if len(widths) > 0:\n",
    "                            left_idx = int(left_ips[0])\n",
    "                            right_idx = int(right_ips[0])\n",
    "                            \n",
    "                            # Add subtle shading\n",
    "                            ax.axvspan(frames[left_idx], frames[right_idx], \n",
    "                                     alpha=0.2, color='red', zorder=0)\n",
    "                \n",
    "                # Formatting\n",
    "                ax.set_xlabel('Frames', fontsize=10)\n",
    "                ax.set_ylabel('ΔF/F', fontsize=10)\n",
    "                ax.set_title(f'ROI {roi_idx + 1} - {\"Active\" if len(peaks) >= 2 else \"Inactive\"} ({len(peaks)} peaks)', fontsize=11, pad=5)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "                \n",
    "                # Add baseline reference\n",
    "                ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "                \n",
    "                # Set y-limits with some padding\n",
    "                y_min, y_max = ax.get_ylim()\n",
    "                y_range = y_max - y_min\n",
    "                ax.set_ylim(y_min - 0.1 * y_range, y_max + 0.1 * y_range)\n",
    "                \n",
    "                if len(peaks) > 0:\n",
    "                    ax.legend(loc='upper right', fontsize=9, frameon=False)\n",
    "                \n",
    "                roi_idx += 1\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            pdf.savefig(fig, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "    \n",
    "    return pdf_filename\n",
    "\n",
    "\n",
    "def create_trace_pdfs_measurement1(df, output_folder, experiment_type):\n",
    "    \"\"\"\n",
    "    Create PDF files with calcium traces for all Measurement 1 files.\n",
    "    \"\"\"\n",
    "    # Create traces subfolder\n",
    "    traces_folder = output_folder\n",
    "    os.makedirs(traces_folder, exist_ok=True)\n",
    "    \n",
    "    # Check if FilePath column exists\n",
    "    if 'FilePath' not in df.columns:\n",
    "        print(\"Warning: FilePath column not found in dataframe. Cannot create trace PDFs.\")\n",
    "        return []\n",
    "    \n",
    "    # Get unique files and their paths (all should be Measurement 1)\n",
    "    unique_files = df[['File', 'FilePath']].drop_duplicates()\n",
    "    \n",
    "    print(f\"\\nCreating trace PDFs for all {len(unique_files)} Measurement 1 files\")\n",
    "    \n",
    "    # Create subfolders by condition\n",
    "    for condition in df['Condition'].unique():\n",
    "        condition_folder = os.path.join(traces_folder, condition.replace(' ', '_').replace('(', '').replace(')', ''))\n",
    "        os.makedirs(condition_folder, exist_ok=True)\n",
    "    \n",
    "    # Process each file\n",
    "    pdf_files_created = []\n",
    "    for idx, (_, row) in enumerate(unique_files.iterrows()):\n",
    "        file_name = row['File']\n",
    "        file_path = row['FilePath']\n",
    "        \n",
    "        # Get condition for this file\n",
    "        condition = df[df['File'] == file_name]['Condition'].iloc[0]\n",
    "        condition_folder = os.path.join(traces_folder, condition.replace(' ', '_').replace('(', '').replace(')', ''))\n",
    "        \n",
    "        print(f\"  Processing traces for: {file_name} ({idx + 1}/{len(unique_files)})\")\n",
    "        \n",
    "        try:\n",
    "            pdf_path = plot_calcium_traces(file_path, condition_folder)\n",
    "            pdf_files_created.append(pdf_path)\n",
    "        except Exception as e:\n",
    "            print(f\"    Error creating traces for {file_name}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nCreated {len(pdf_files_created)} PDF files with calcium traces\")\n",
    "    \n",
    "    # Create summary PDF with example traces from each condition\n",
    "    create_trace_summary_pdf(df, traces_folder, experiment_type)\n",
    "    \n",
    "    return pdf_files_created\n",
    "\n",
    "\n",
    "def create_trace_summary_pdf(df, traces_folder, experiment_type):\n",
    "    \"\"\"Create a summary PDF with example traces from each condition.\"\"\"\n",
    "    summary_pdf = os.path.join(traces_folder, f'{experiment_type}_Measurement1_trace_examples.pdf')\n",
    "    \n",
    "    conditions = sorted(df['Condition'].unique())\n",
    "    \n",
    "    with matplotlib.backends.backend_pdf.PdfPages(summary_pdf) as pdf:\n",
    "        # Create overview page\n",
    "        fig = plt.figure(figsize=(12, 9))\n",
    "        fig.suptitle(f'{experiment_type} - Example Calcium Traces by Condition (Measurement 1)', fontsize=16)\n",
    "        \n",
    "        # Create grid of subplots\n",
    "        n_conditions = len(conditions)\n",
    "        n_cols = 2\n",
    "        n_rows = (n_conditions + n_cols - 1) // n_cols\n",
    "        \n",
    "        for idx, condition in enumerate(conditions):\n",
    "            ax = plt.subplot(n_rows, n_cols, idx + 1)\n",
    "            \n",
    "            # Get an example active ROI from this condition\n",
    "            active_rois = df[(df['Condition'] == condition) & (df['IsActive'])]\n",
    "            \n",
    "            if len(active_rois) > 0:\n",
    "                # Pick a representative ROI (one with median number of peaks)\n",
    "                median_peaks = active_rois['NumPeaks'].median()\n",
    "                example_roi = active_rois.iloc[(active_rois['NumPeaks'] - median_peaks).abs().argsort()[:1]]\n",
    "                \n",
    "                file_path = example_roi['FilePath'].iloc[0]\n",
    "                roi_index = example_roi['ROI_Index'].iloc[0] if 'ROI_Index' in example_roi.columns else 1\n",
    "                \n",
    "                # Read and plot the trace\n",
    "                try:\n",
    "                    data = pd.read_csv(file_path, header=None, skiprows=1)\n",
    "                    frames = data[0].dropna().values\n",
    "                    \n",
    "                    # Use the stored ROI index\n",
    "                    if roi_index + 1 < len(data.columns):\n",
    "                        intensity = data[roi_index + 1].dropna().values\n",
    "                    else:\n",
    "                        intensity = data[1].dropna().values  # Use first ROI as fallback\n",
    "                    \n",
    "                    baseline = np.mean(intensity)\n",
    "                    if baseline > 0:\n",
    "                        dff = (intensity - baseline) / baseline\n",
    "                        \n",
    "                        # Plot\n",
    "                        ax.plot(frames, dff, 'k-', linewidth=1)\n",
    "                        \n",
    "                        # Find and mark peaks with specified parameters\n",
    "                        peaks, _ = find_peaks(dff, prominence=0.2, distance=5, width=1)\n",
    "                        if len(peaks) > 0:\n",
    "                            ax.plot(frames[peaks], dff[peaks], 'ro', markersize=4)\n",
    "                        \n",
    "                        ax.set_title(f'{condition}\\n({len(peaks)} peaks)', fontsize=12)\n",
    "                        ax.set_xlabel('Frames', fontsize=10)\n",
    "                        ax.set_ylabel('ΔF/F', fontsize=10)\n",
    "                        ax.grid(True, alpha=0.3)\n",
    "                        ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'No valid example', ha='center', va='center', transform=ax.transAxes)\n",
    "                except Exception as e:\n",
    "                    ax.text(0.5, 0.5, f'Error: {str(e)[:20]}...', ha='center', va='center', transform=ax.transAxes)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'No active ROIs', ha='center', va='center', transform=ax.transAxes)\n",
    "            \n",
    "            ax.set_xlim(0, 100)  # Show first 100 frames\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    \n",
    "    print(f\"Created summary PDF: {summary_pdf}\")\n",
    "\n",
    "\n",
    "# ## Statistical Functions\n",
    "\n",
    "def perform_statistical_analysis(df, metric, conditions, control_condition):\n",
    "    \"\"\"\n",
    "    Perform comprehensive statistical analysis comparing all conditions to control.\n",
    "    Uses Shapiro-Wilk test for normality assessment, then chooses appropriate test:\n",
    "    - Normal distribution: Independent t-test\n",
    "    - Non-normal distribution or small samples: Mann-Whitney U test\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'metric': metric,\n",
    "        'control': control_condition,\n",
    "        'normality': {},\n",
    "        'descriptive': {},\n",
    "        'comparisons': []\n",
    "    }\n",
    "    \n",
    "    # Descriptive statistics and normality test for each condition\n",
    "    for cond in conditions:\n",
    "        cond_data = df[df['Condition'] == cond][metric].dropna()\n",
    "        if len(cond_data) >= 3:\n",
    "            # Normality test (Shapiro-Wilk)\n",
    "            stat, p_val = shapiro(cond_data)\n",
    "            is_normal = p_val > 0.05\n",
    "            \n",
    "            # Descriptive stats\n",
    "            results['descriptive'][cond] = {\n",
    "                'n': len(cond_data),\n",
    "                'mean': np.mean(cond_data),\n",
    "                'median': np.median(cond_data),\n",
    "                'std': np.std(cond_data),\n",
    "                'sem': sem(cond_data),\n",
    "                'min': np.min(cond_data),\n",
    "                'max': np.max(cond_data)\n",
    "            }\n",
    "            results['normality'][cond] = {\n",
    "                'is_normal': is_normal,\n",
    "                'shapiro_p': p_val\n",
    "            }\n",
    "        else:\n",
    "            results['descriptive'][cond] = {'n': len(cond_data)}\n",
    "            results['normality'][cond] = {'is_normal': False, 'shapiro_p': np.nan}\n",
    "    \n",
    "    # Compare each condition to control\n",
    "    control_data = df[df['Condition'] == control_condition][metric].dropna()\n",
    "    if len(control_data) >= 2:\n",
    "        for cond in conditions:\n",
    "            if cond == control_condition:\n",
    "                continue\n",
    "                \n",
    "            cond_data = df[df['Condition'] == cond][metric].dropna()\n",
    "            if len(cond_data) >= 2:\n",
    "                # Choose test based on normality\n",
    "                both_normal = (results['normality'][control_condition]['is_normal'] and \n",
    "                             results['normality'][cond]['is_normal'])\n",
    "                \n",
    "                if both_normal and len(control_data) > 20 and len(cond_data) > 20:\n",
    "                    # Use t-test for normal data with sufficient sample size\n",
    "                    stat, p_val = ttest_ind(control_data, cond_data)\n",
    "                    test_used = \"Independent t-test\"\n",
    "                else:\n",
    "                    # Use Mann-Whitney U for non-normal or small samples\n",
    "                    stat, p_val = mannwhitneyu(control_data, cond_data, alternative='two-sided')\n",
    "                    test_used = \"Mann-Whitney U\"\n",
    "                \n",
    "                # Calculate effect size (Cohen's d)\n",
    "                pooled_std = np.sqrt((np.std(control_data)**2 + np.std(cond_data)**2) / 2)\n",
    "                if pooled_std > 0:\n",
    "                    cohens_d = (np.mean(cond_data) - np.mean(control_data)) / pooled_std\n",
    "                else:\n",
    "                    cohens_d = 0\n",
    "                \n",
    "                results['comparisons'].append({\n",
    "                    'comparison': f\"{cond} vs {control_condition}\",\n",
    "                    'test': test_used,\n",
    "                    'statistic': stat,\n",
    "                    'p_value': p_val,\n",
    "                    'significant': p_val < 0.05,\n",
    "                    'cohens_d': cohens_d,\n",
    "                    'mean_diff': np.mean(cond_data) - np.mean(control_data)\n",
    "                })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def generate_stats_report(df, output_path, experiment_name, experiment_type=\"RNA\"):\n",
    "    \"\"\"Generate comprehensive statistical report with UTF-8 encoding.\"\"\"\n",
    "    # Determine control condition\n",
    "    control_condition = 'Control (Scr)' if experiment_type == \"RNA\" else 'WT'\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"COMPREHENSIVE STATISTICAL ANALYSIS REPORT\\n\")\n",
    "        f.write(f\"{experiment_name}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        \n",
    "        # Analysis methodology\n",
    "        f.write(\"ANALYSIS METHODOLOGY\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(\"Data Selection:\\n\")\n",
    "        f.write(\"  - Only Measurement 1 data analyzed\\n\")\n",
    "        f.write(f\"  - RNA: Files with 'Meas1' in filename\\n\")\n",
    "        f.write(f\"  - Chemical: Files with '1001' in filename\\n\")\n",
    "        f.write(\"Peak Detection Parameters:\\n\")\n",
    "        f.write(\"  - Prominence threshold: > 0.2\\n\")\n",
    "        f.write(\"  - Minimum peak separation: 5 frames\\n\")\n",
    "        f.write(\"  - Active cells: ≥ 2 peaks\\n\")\n",
    "        f.write(\"Outlier Removal:\\n\")\n",
    "        f.write(\"  - Method: Z-score\\n\")\n",
    "        f.write(\"  - Threshold: 3.0\\n\")\n",
    "        f.write(\"Statistical Tests:\\n\")\n",
    "        f.write(\"  - Normality assessment: Shapiro-Wilk test\\n\")\n",
    "        f.write(\"  - Comparison tests: Mann-Whitney U (non-normal) or t-test (normal)\\n\\n\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        f.write(\"OVERALL SUMMARY (Measurement 1 Only)\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(f\"Total ROIs analyzed: {len(df)}\\n\")\n",
    "        f.write(f\"Active ROIs (≥2 peaks): {df['IsActive'].sum()} ({df['IsActive'].mean()*100:.1f}%)\\n\")\n",
    "        f.write(f\"Conditions: {sorted(df['Condition'].unique())}\\n\")\n",
    "        f.write(f\"Control condition: {control_condition}\\n\\n\")\n",
    "        \n",
    "        # Activity by condition\n",
    "        f.write(\"ACTIVITY BY CONDITION\\n\")\n",
    "        f.write(\"-\"*40 + \"\\n\")\n",
    "        f.write(f\"{'Condition':<20} {'Total ROIs':<12} {'Active':<12} {'Percent':<12}\\n\")\n",
    "        f.write(\"-\"*60 + \"\\n\")\n",
    "        \n",
    "        for cond in sorted(df['Condition'].unique()):\n",
    "            cond_df = df[df['Condition'] == cond]\n",
    "            active = cond_df['IsActive'].sum()\n",
    "            total = len(cond_df)\n",
    "            percent = active/total*100 if total > 0 else 0\n",
    "            f.write(f\"{cond:<20} {total:<12} {active:<12} {percent:<12.1f}%\\n\")\n",
    "        \n",
    "        # Analyze active cells only\n",
    "        df_active = df[df['IsActive']].copy()\n",
    "        \n",
    "        if len(df_active) > 0:\n",
    "            f.write(\"\\n\\nDETAILED STATISTICAL ANALYSIS (Active Cells Only)\\n\")\n",
    "            f.write(\"=\"*80 + \"\\n\\n\")\n",
    "            \n",
    "            metrics = ['NumPeaks', 'Amplitude', 'Slope', 'FWHM']\n",
    "            conditions = sorted(df_active['Condition'].unique())\n",
    "            \n",
    "            for metric in metrics:\n",
    "                f.write(f\"\\n{metric.upper()}\\n\")\n",
    "                f.write(\"-\"*60 + \"\\n\\n\")\n",
    "                \n",
    "                # Run statistical analysis\n",
    "                stats_results = perform_statistical_analysis(df_active, metric, conditions, control_condition)\n",
    "                \n",
    "                # Descriptive statistics table\n",
    "                f.write(\"Descriptive Statistics:\\n\")\n",
    "                f.write(f\"{'Condition':<20} {'N':<6} {'Mean ± SEM':<15} {'Median':<10} {'Min-Max':<20}\\n\")\n",
    "                f.write(\"-\"*75 + \"\\n\")\n",
    "                \n",
    "                for cond in conditions:\n",
    "                    if cond in stats_results['descriptive']:\n",
    "                        desc = stats_results['descriptive'][cond]\n",
    "                        if desc['n'] > 0:\n",
    "                            mean_sem = f\"{desc['mean']:.3f} ± {desc['sem']:.3f}\"\n",
    "                            min_max = f\"{desc['min']:.3f} - {desc['max']:.3f}\"\n",
    "                            f.write(f\"{cond:<20} {desc['n']:<6} {mean_sem:<15} \"\n",
    "                                   f\"{desc['median']:<10.3f} {min_max:<20}\\n\")\n",
    "                \n",
    "                # Normality test results\n",
    "                f.write(\"\\nNormality Test (Shapiro-Wilk):\\n\")\n",
    "                for cond in conditions:\n",
    "                    if cond in stats_results['normality']:\n",
    "                        norm = stats_results['normality'][cond]\n",
    "                        if not np.isnan(norm['shapiro_p']):\n",
    "                            normal_str = \"Normal\" if norm['is_normal'] else \"Not Normal\"\n",
    "                            f.write(f\"{cond}: p = {norm['shapiro_p']:.4f} ({normal_str})\\n\")\n",
    "                \n",
    "                # Statistical comparisons vs control\n",
    "                f.write(f\"\\nStatistical Comparisons (vs {control_condition}):\\n\")\n",
    "                f.write(\"-\"*60 + \"\\n\")\n",
    "                \n",
    "                for comp in stats_results['comparisons']:\n",
    "                    sig_str = \"***\" if comp['p_value'] < 0.001 else \"**\" if comp['p_value'] < 0.01 else \"*\" if comp['p_value'] < 0.05 else \"ns\"\n",
    "                    effect_size = \"Large\" if abs(comp['cohens_d']) > 0.8 else \"Medium\" if abs(comp['cohens_d']) > 0.5 else \"Small\"\n",
    "                    \n",
    "                    f.write(f\"{comp['comparison']}: {comp['test']}\\n\")\n",
    "                    f.write(f\"  p-value: {comp['p_value']:.4f} ({sig_str})\\n\")\n",
    "                    f.write(f\"  Mean difference: {comp['mean_diff']:.3f}\\n\")\n",
    "                    f.write(f\"  Effect size (Cohen's d): {comp['cohens_d']:.3f} ({effect_size})\\n\\n\")\n",
    "        \n",
    "        # Footer\n",
    "        f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "        f.write(\"STATISTICAL NOTATION:\\n\")\n",
    "        f.write(\"ns: not significant (p > 0.05)\\n\")\n",
    "        f.write(\"*: p < 0.05\\n\")\n",
    "        f.write(\"**: p < 0.01\\n\")\n",
    "        f.write(\"***: p < 0.001\\n\")\n",
    "        f.write(\"\\nEffect Size Interpretation (Cohen's d):\\n\")\n",
    "        f.write(\"Small: |d| < 0.5\\n\")\n",
    "        f.write(\"Medium: 0.5 ≤ |d| < 0.8\\n\")\n",
    "        f.write(\"Large: |d| ≥ 0.8\\n\")\n",
    "\n",
    "\n",
    "# ## Plotting Functions\n",
    "\n",
    "def create_analysis_plots(df, metrics, output_folder, title_suffix=\"\", experiment_type=\"RNA\"):\n",
    "    \"\"\"Create analysis plots for active cells with updated violin plots and statistics.\"\"\"\n",
    "    df_active_original = df[df['IsActive']].copy()\n",
    "    \n",
    "    if len(df_active_original) == 0:\n",
    "        print(\"No active cells found!\")\n",
    "        return\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Define condition order and control based on experiment type\n",
    "    if experiment_type == \"RNA\":\n",
    "        condition_order = ['Control (Scr)', 'saRNA', 'siRNA']\n",
    "        control_condition = 'Control (Scr)'\n",
    "        color_map = {\n",
    "            'Control (Scr)': '#1f77b4',  # Blue\n",
    "            'saRNA': '#ff7f0e',          # Orange\n",
    "            'siRNA': '#2ca02c'           # Green\n",
    "        }\n",
    "    else:\n",
    "        condition_order = ['WT', 'Nav1.1 activator', 'PTZ', 'Veratridine']\n",
    "        control_condition = 'WT'\n",
    "        color_map = {\n",
    "            'WT': '#1f77b4',\n",
    "            'Nav1.1 activator': '#ff7f0e',\n",
    "            'PTZ': '#2ca02c',\n",
    "            'Veratridine': '#d62728'\n",
    "        }\n",
    "    \n",
    "    # Filter to only include conditions present in data\n",
    "    conditions = [c for c in condition_order if c in df_active_original['Condition'].unique()]\n",
    "    colors = [color_map.get(c, '#666666') for c in conditions]\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Remove outliers for THIS metric only\n",
    "        df_active = remove_outliers_zscore(df_active_original.copy(), metric, threshold=3.0)\n",
    "        \n",
    "        # Prepare data in correct order\n",
    "        data_to_plot = []\n",
    "        positions = []\n",
    "        for i, cond in enumerate(conditions):\n",
    "            cond_data = df_active[df_active['Condition'] == cond][metric].values\n",
    "            if len(cond_data) > 0:\n",
    "                data_to_plot.append(cond_data)\n",
    "                positions.append(i + 1)\n",
    "        \n",
    "        # Skip if no data to plot\n",
    "        if not data_to_plot:\n",
    "            continue\n",
    "            \n",
    "        # Create violin plot with error handling\n",
    "        try:\n",
    "            parts = ax.violinplot(data_to_plot, positions=positions, \n",
    "                                 showmeans=False, showmedians=False, showextrema=False)\n",
    "            \n",
    "            # Customize violins\n",
    "            for i, pc in enumerate(parts['bodies']):\n",
    "                pc.set_facecolor(colors[i])\n",
    "                pc.set_alpha(0.7)\n",
    "                pc.set_edgecolor('black')\n",
    "                pc.set_linewidth(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not create violin plot for {metric}: {str(e)}\")\n",
    "            # Fallback to box plot\n",
    "            bp = ax.boxplot(data_to_plot, positions=positions, patch_artist=True)\n",
    "            for i, box in enumerate(bp['boxes']):\n",
    "                box.set_facecolor(colors[i])\n",
    "                box.set_alpha(0.7)\n",
    "        \n",
    "        # Add only mean lines\n",
    "        for i, (pos, data) in enumerate(zip(positions, data_to_plot)):\n",
    "            if len(data) > 0:\n",
    "                mean_val = np.mean(data)\n",
    "                ax.hlines(mean_val, pos-0.2, pos+0.2, colors='red', linewidth=3)\n",
    "        \n",
    "        # Run statistical analysis\n",
    "        stats_results = perform_statistical_analysis(df_active, metric, conditions, control_condition)\n",
    "        \n",
    "        # Add significance annotations\n",
    "        y_max = ax.get_ylim()[1]\n",
    "        y_range = ax.get_ylim()[1] - ax.get_ylim()[0]\n",
    "        annotation_height = y_max + 0.05 * y_range\n",
    "        \n",
    "        for comp in stats_results['comparisons']:\n",
    "            # Find positions for the comparison\n",
    "            comp_parts = comp['comparison'].split(' vs ')\n",
    "            if comp_parts[0] in conditions and comp_parts[1] in conditions:\n",
    "                idx1 = conditions.index(comp_parts[0])\n",
    "                idx2 = conditions.index(comp_parts[1])\n",
    "                \n",
    "                if comp['significant']:\n",
    "                    sig_str = \"***\" if comp['p_value'] < 0.001 else \"**\" if comp['p_value'] < 0.01 else \"*\"\n",
    "                    \n",
    "                    # Draw bracket\n",
    "                    x1, x2 = positions[idx1], positions[idx2]\n",
    "                    ax.plot([x1, x1, x2, x2], \n",
    "                           [annotation_height - 0.02*y_range, annotation_height, \n",
    "                            annotation_height, annotation_height - 0.02*y_range], \n",
    "                           'k-', linewidth=1)\n",
    "                    ax.text((x1 + x2) / 2, annotation_height + 0.01*y_range, sig_str, \n",
    "                           ha='center', va='bottom', fontsize=12)\n",
    "                    annotation_height += 0.08 * y_range\n",
    "        \n",
    "        # Labels and formatting\n",
    "        ax.set_xticks(positions)\n",
    "        ax.set_xticklabels(conditions, rotation=45, ha='right')\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.set_title(metric)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add sample sizes\n",
    "        y_min = ax.get_ylim()[0]\n",
    "        for i, (pos, cond) in enumerate(zip(positions, conditions)):\n",
    "            n = len(df_active[df_active['Condition'] == cond][metric])\n",
    "            ax.text(pos, y_min - 0.05 * y_range, \n",
    "                   f'n={n}', ha='center', fontsize=10, weight='bold')\n",
    "        \n",
    "        # Adjust y-axis to make room for n= labels and significance annotations\n",
    "        ax.set_ylim(bottom=y_min - 0.1 * y_range, \n",
    "                   top=max(ax.get_ylim()[1], annotation_height + 0.05 * y_range))\n",
    "    \n",
    "    plt.suptitle(f'Calcium Imaging Analysis - Measurement 1{title_suffix}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save as both PNG and PDF with error handling\n",
    "    try:\n",
    "        plt.savefig(os.path.join(output_folder, f'analysis_measurement1{title_suffix.replace(\" \", \"_\")}.png'), \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(os.path.join(output_folder, f'analysis_measurement1{title_suffix.replace(\" \", \"_\")}.pdf'), \n",
    "                    format='pdf', bbox_inches='tight')\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save plots: {str(e)}\")\n",
    "    finally:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def create_activity_plot(df, output_folder, title_suffix=\"\", experiment_type=\"RNA\"):\n",
    "    \"\"\"Create activity summary plot with individual file dots and SD error bars.\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    \n",
    "    # Define condition order based on experiment type\n",
    "    if experiment_type == \"RNA\":\n",
    "        condition_order = ['Control (Scr)', 'saRNA', 'siRNA']\n",
    "        control_condition = 'Control (Scr)'\n",
    "        color_map = {\n",
    "            'Control (Scr)': '#1f77b4',  # Blue\n",
    "            'saRNA': '#ff7f0e',          # Orange\n",
    "            'siRNA': '#2ca02c'           # Green\n",
    "        }\n",
    "    else:\n",
    "        condition_order = ['WT', 'Nav1.1 activator', 'PTZ', 'Veratridine']\n",
    "        control_condition = 'WT'\n",
    "        color_map = {\n",
    "            'WT': '#1f77b4',\n",
    "            'Nav1.1 activator': '#ff7f0e',\n",
    "            'PTZ': '#2ca02c',\n",
    "            'Veratridine': '#d62728'\n",
    "        }\n",
    "    \n",
    "    # Filter to only include conditions present in data\n",
    "    conditions = [c for c in condition_order if c in df['Condition'].unique()]\n",
    "    \n",
    "    # Calculate activity by condition and FILE\n",
    "    activity_by_file = []\n",
    "    \n",
    "    for cond in conditions:\n",
    "        cond_df = df[df['Condition'] == cond]\n",
    "        \n",
    "        # Get unique files for this condition\n",
    "        unique_files = cond_df['File'].unique()\n",
    "        \n",
    "        for file in unique_files:\n",
    "            file_df = cond_df[cond_df['File'] == file]\n",
    "            total = len(file_df)\n",
    "            active = len(file_df[file_df['IsActive']])\n",
    "            if total > 0:\n",
    "                activity_by_file.append({\n",
    "                    'Condition': cond,\n",
    "                    'File': file,\n",
    "                    'Active': active,\n",
    "                    'Total': total,\n",
    "                    'Percent': active/total*100\n",
    "                })\n",
    "    \n",
    "    activity_detail_df = pd.DataFrame(activity_by_file)\n",
    "    \n",
    "    # Calculate overall statistics by condition\n",
    "    activity_summary = []\n",
    "    for cond in conditions:\n",
    "        cond_data = activity_detail_df[activity_detail_df['Condition'] == cond]['Percent']\n",
    "        if len(cond_data) > 0:\n",
    "            mean_percent = cond_data.mean()\n",
    "            std_percent = cond_data.std()\n",
    "            sem_percent = cond_data.sem()\n",
    "            total_cells = df[df['Condition'] == cond].shape[0]\n",
    "            activity_summary.append({\n",
    "                'Condition': cond,\n",
    "                'MeanPercent': mean_percent,\n",
    "                'StdPercent': std_percent,\n",
    "                'SemPercent': sem_percent,\n",
    "                'TotalCells': total_cells\n",
    "            })\n",
    "    \n",
    "    activity_summary_df = pd.DataFrame(activity_summary)\n",
    "    \n",
    "    # Create bar plot with SD error bars\n",
    "    x_positions = np.arange(len(conditions))\n",
    "    colors = [color_map.get(c, '#666666') for c in conditions]\n",
    "    \n",
    "    # Plot bars with error bars\n",
    "    bars = ax.bar(x_positions, activity_summary_df['MeanPercent'], \n",
    "                  yerr=activity_summary_df['StdPercent'],\n",
    "                  color=colors, alpha=0.6, edgecolor='black', linewidth=1,\n",
    "                  capsize=5, error_kw={'linewidth': 2})\n",
    "    \n",
    "    # Add individual file dots\n",
    "    np.random.seed(42)  # For reproducible jitter\n",
    "    for i, cond in enumerate(conditions):\n",
    "        cond_data = activity_detail_df[activity_detail_df['Condition'] == cond]\n",
    "        if not cond_data.empty:\n",
    "            # Add some jitter to x positions for better visibility\n",
    "            jitter = np.random.normal(0, 0.08, len(cond_data))\n",
    "            x_dots = np.full(len(cond_data), i) + jitter\n",
    "            \n",
    "            # Plot dots for each file\n",
    "            ax.scatter(x_dots, cond_data['Percent'], \n",
    "                      color='black', s=80, alpha=0.7, zorder=10,\n",
    "                      edgecolors='white', linewidth=1.5)\n",
    "    \n",
    "    # Run statistical analysis for activity percentages\n",
    "    if len(activity_detail_df) > 0:\n",
    "        # Prepare data for statistical analysis\n",
    "        stats_df = pd.DataFrame()\n",
    "        for _, row in activity_detail_df.iterrows():\n",
    "            stats_df = pd.concat([stats_df, pd.DataFrame({\n",
    "                'Condition': [row['Condition']],\n",
    "                'ActivityPercent': [row['Percent']]\n",
    "            })], ignore_index=True)\n",
    "        \n",
    "        stats_results = perform_statistical_analysis(stats_df, 'ActivityPercent', \n",
    "                                                   conditions, control_condition)\n",
    "        \n",
    "        # Add significance annotations\n",
    "        y_max = max(activity_detail_df['Percent'].max() * 1.1 if not activity_detail_df.empty else 50, \n",
    "                   (activity_summary_df['MeanPercent'] + activity_summary_df['StdPercent']).max() * 1.1 if not activity_summary_df.empty else 50)\n",
    "        annotation_height = y_max\n",
    "        \n",
    "        if 'comparisons' in stats_results:\n",
    "            for comp in stats_results['comparisons']:\n",
    "                if comp['significant']:\n",
    "                    # Find positions for the comparison\n",
    "                    comp_parts = comp['comparison'].split(' vs ')\n",
    "                    if comp_parts[0] in conditions and comp_parts[1] in conditions:\n",
    "                        idx1 = conditions.index(comp_parts[0])\n",
    "                        idx2 = conditions.index(comp_parts[1])\n",
    "                        \n",
    "                        sig_str = \"***\" if comp['p_value'] < 0.001 else \"**\" if comp['p_value'] < 0.01 else \"*\"\n",
    "                        \n",
    "                        # Draw bracket\n",
    "                        bracket_height = annotation_height\n",
    "                        ax.plot([idx1, idx1, idx2, idx2], \n",
    "                               [bracket_height - 1, bracket_height, bracket_height, bracket_height - 1], \n",
    "                               'k-', linewidth=1)\n",
    "                        ax.text((idx1 + idx2) / 2, bracket_height + 0.5, sig_str, \n",
    "                               ha='center', va='bottom', fontsize=14, weight='bold')\n",
    "                        annotation_height += 5\n",
    "    \n",
    "    # Labels and formatting\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(conditions, rotation=45, ha='right', fontsize=12)\n",
    "    ax.set_ylabel('Active Cells (%)', fontsize=14)\n",
    "    ax.set_title(f'Cell Activity by Condition - Measurement 1{title_suffix}\\n(dots show individual files, bars show mean ± SD)', \n",
    "                fontsize=14)\n",
    "    ax.set_ylim(0, max(annotation_height + 2, y_max))\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add text annotations on bars\n",
    "    for i, (bar, row) in enumerate(zip(bars, activity_summary_df.itertuples())):\n",
    "        height = row.MeanPercent\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + row.StdPercent + 1,\n",
    "               f'{row.MeanPercent:.1f}%\\n(n={row.TotalCells})',\n",
    "               ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Add legend if significant differences found\n",
    "    if 'comparisons' in stats_results and any(comp['significant'] for comp in stats_results['comparisons']):\n",
    "        ax.text(0.02, 0.98, 'Statistical significance vs ' + control_condition, \n",
    "               transform=ax.transAxes, va='top', ha='left', fontsize=10,\n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save as both PNG and PDF\n",
    "    plt.savefig(os.path.join(output_folder, f'activity_measurement1{title_suffix.replace(\" \", \"_\")}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(os.path.join(output_folder, f'activity_measurement1{title_suffix.replace(\" \", \"_\")}.pdf'), \n",
    "                format='pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ## Main Analysis Pipeline\n",
    "\n",
    "def analyze_experiment_measurement1(base_path, experiment_name, experiment_type, output_base):\n",
    "    \"\"\"Run complete analysis for an experiment - Measurement 1 only.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analyzing: {experiment_name} - MEASUREMENT 1 ONLY\")\n",
    "    print(f\"Path: {base_path}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create output directories\n",
    "    exp_output = os.path.join(output_base, experiment_name.replace(' ', '_'))\n",
    "    subdirs = {\n",
    "        'figures': os.path.join(exp_output, 'Figures'),\n",
    "        'stats': os.path.join(exp_output, 'Statistics'),\n",
    "        'data': os.path.join(exp_output, 'Data'),\n",
    "        'traces': os.path.join(exp_output, 'Calcium_Traces')\n",
    "    }\n",
    "    \n",
    "    for dir_path in subdirs.values():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Collect data - Measurement 1 only\n",
    "    print(\"\\nCollecting Measurement 1 data...\")\n",
    "    df, parsing_log = collect_measurement1_data(base_path, experiment_type)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No Measurement 1 data found!\")\n",
    "        return\n",
    "    \n",
    "    # Save parsing log\n",
    "    parsing_log.to_csv(os.path.join(subdirs['data'], 'file_parsing_log_measurement1.csv'), index=False)\n",
    "    \n",
    "    print(f\"\\nMeasurement 1 Summary:\")\n",
    "    print(f\"  Total ROIs: {len(df)}\")\n",
    "    print(f\"  Active ROIs: {df['IsActive'].sum()} ({df['IsActive'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Conditions: {sorted(df['Condition'].unique())}\")\n",
    "    \n",
    "    # Save raw data\n",
    "    df.to_csv(os.path.join(subdirs['data'], 'measurement1_data.csv'), index=False)\n",
    "    \n",
    "    # Define metrics\n",
    "    metrics = ['NumPeaks', 'Amplitude', 'Slope', 'FWHM']\n",
    "    \n",
    "    # Create analysis plots\n",
    "    print(f\"\\nCreating analysis plots...\")\n",
    "    create_analysis_plots(df, metrics, subdirs['figures'], \"\", experiment_type)\n",
    "    create_activity_plot(df, subdirs['figures'], \"\", experiment_type)\n",
    "    \n",
    "    # Generate statistics report\n",
    "    print(f\"\\nGenerating statistical report...\")\n",
    "    generate_stats_report(df, os.path.join(subdirs['stats'], 'measurement_1_stats.txt'), \n",
    "                        f\"{experiment_name} - Measurement 1\", experiment_type)\n",
    "    \n",
    "    # Create calcium trace PDFs\n",
    "    print(\"\\nGenerating calcium trace PDFs...\")\n",
    "    create_trace_pdfs_measurement1(df, subdirs['traces'], experiment_type)\n",
    "    \n",
    "    print(f\"\\nAnalysis complete! Results saved to: {exp_output}\")\n",
    "    print(f\"  - Parsing log: Data/file_parsing_log_measurement1.csv\")\n",
    "    print(f\"  - Calcium traces: Calcium_Traces/\")\n",
    "    print(f\"  - Statistics: Statistics/measurement_1_stats.txt\")\n",
    "    print(f\"  - Figures: Figures/\")\n",
    "\n",
    "\n",
    "# ## Run Analysis\n",
    "\n",
    "# Create timestamp for output\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_base = f\"CalciumImaging_Measurement1_Results_{timestamp}\"\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_base}\\n\")\n",
    "\n",
    "# RNA Interference Experiment\n",
    "rna_path = r'H:\\Scripts June PhD\\Calcium imaging June\\Calcium imaging Scr, saRNA and siRNA'\n",
    "if os.path.exists(rna_path):\n",
    "    analyze_experiment_measurement1(rna_path, \"RNA_Interference\", \"RNA\", output_base)\n",
    "else:\n",
    "    print(f\"RNA path not found: {rna_path}\")\n",
    "\n",
    "# Chemical Treatments Experiment  \n",
    "chem_path = r'H:\\Scripts June PhD\\Calcium imaging June\\20250303 Chemicals Results'\n",
    "if os.path.exists(chem_path):\n",
    "    analyze_experiment_measurement1(chem_path, \"Chemical_Treatments\", \"Chemical\", output_base)\n",
    "else:\n",
    "    print(f\"Chemical path not found: {chem_path}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL ANALYSES COMPLETE!\")\n",
    "print(f\"Results saved to: {output_base}\")\n",
    "print(f\"Figures saved as both PNG and PDF formats\")\n",
    "print(f\"Calcium trace PDFs created for all Measurement 1 files\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ## Summary\n",
    "# \n",
    "# Key changes in this version:\n",
    "# 1. **Only analyzes Measurement 1 files**:\n",
    "#    - RNA: Only files with \"Meas1\" in filename\n",
    "#    - Chemical: Only files with \"1001\" in filename (not \"2001\")\n",
    "# 2. **Removed duplicate processing** - tracks processed files\n",
    "# 3. **Creates trace PDFs for ALL Measurement 1 files** (not just a sample)\n",
    "# 4. **Single analysis output** - no separate \"Other Measurements\" folder\n",
    "# 5. **Maintains all methodology parameters**:\n",
    "#    - Peak detection: prominence > 0.2, separation = 5 frames\n",
    "#    - Active cells: ≥ 2 peaks  \n",
    "#    - Z-score outlier removal with threshold 3.0\n",
    "#    - Shapiro-Wilk → Mann-Whitney U or t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd7e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
